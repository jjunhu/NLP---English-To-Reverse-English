# Simple Recurrent Unit (SRU) and T5 Implementation 

This repository contains an implementation of the Simple Recurrent Unit (SRU), a neural network architecture for processing sequential data with improved efficiency and performance.

## Introduction

The SRU is designed to be a faster alternative to traditional RNNs while maintaining the capacity to capture long-term dependencies. It achieves this by simplifying the recurrent computation, which reduces the complexity and computational cost.

## Installation

To use the SRU implementation, clone the repository:

