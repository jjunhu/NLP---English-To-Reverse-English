{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (1.22.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import pandas as pd \n",
    "\n",
    "def reverse_sentence(sentence):\n",
    "    return sentence[::-1]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" Clean the text by removing or replacing unwanted characters. \"\"\"\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = text.replace('\\t', ' ').replace('\\n', ' ')  # Replace tabs and new lines\n",
    "    return text\n",
    "\n",
    "def prepare_data(dataset, num_samples=10000, train_split=0.8, val_split=0.1):\n",
    "    data = []\n",
    "    for article in dataset['train']:\n",
    "        text = clean_text(article['article'])\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "        for sentence in sentences:\n",
    "            if sentence:\n",
    "                reversed_sentence = reverse_sentence(sentence)\n",
    "                data.append((sentence, reversed_sentence))\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    data = data[:num_samples]  # Limit the total number of rows\n",
    "    df = pd.DataFrame(data, columns=['sentence', 'reversed'])\n",
    "\n",
    "    # Split the data\n",
    "    train_size = int(len(df) * train_split)\n",
    "    val_size = int(len(df) * val_split)\n",
    "    train_df = df[:train_size]\n",
    "    val_df = df[train_size:train_size + val_size]\n",
    "    test_df = df[train_size + val_size:]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Prepare the dataset and split\n",
    "train_df, val_df, test_df = prepare_data(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train.csv', sep='\\t', index=False)\n",
    "val_df.to_csv('data/val.csv', sep='\\t', index=False)\n",
    "test_df.to_csv('data/test.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86db3016a89f4ad1845a177307ef6b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f1cdfc8a2a491ea5e84547aed05ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8131351ca24bb2a87195b16ba45716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf8cbecfb94eebac965deb4b3b92a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d51610a05a74d9698388cf466945e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02e1148c9c14a6e8df14a4af2030607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "raw_datasets = load_dataset('csv', data_files={'train': 'data/train.csv', 'validation': 'data/val.csv', 'test': 'data/test.csv'}, delimiter='\\t', column_names=['input', 'target'])\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [f\"reverse: {sentence}\" for sentence in examples['input']]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['target'], max_length=128, padding='max_length', truncation=True)\n",
    "\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d33f1cb665f4aa08895a31a38707098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9849, 'learning_rate': 1.3346640053226881e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01fb7e3950f4a7790f8c9e44d386a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8315600156784058, 'eval_runtime': 5.0463, 'eval_samples_per_second': 198.364, 'eval_steps_per_second': 12.484, 'epoch': 1.0}\n",
      "{'loss': 1.9165, 'learning_rate': 6.69328010645376e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a46c2c8ad6442a39202b1d24392aba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7883822917938232, 'eval_runtime': 5.0412, 'eval_samples_per_second': 198.564, 'eval_steps_per_second': 12.497, 'epoch': 2.0}\n",
      "{'loss': 1.8898, 'learning_rate': 3.992015968063872e-08, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c686742a3443c8808fba979cc2e31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7752636671066284, 'eval_runtime': 5.0264, 'eval_samples_per_second': 199.15, 'eval_steps_per_second': 12.534, 'epoch': 3.0}\n",
      "{'train_runtime': 528.2259, 'train_samples_per_second': 45.441, 'train_steps_per_second': 2.845, 'train_loss': 1.929679704997354, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1503, training_loss=1.929679704997354, metrics={'train_runtime': 528.2259, 'train_samples_per_second': 45.441, 'train_steps_per_second': 2.845, 'train_loss': 1.929679704997354, 'epoch': 3.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# Training Arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanhu/anaconda3/envs/tf_metal/lib/python3.8/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello world\n",
      "Reversed: .shtiw eht eht\n"
     ]
    }
   ],
   "source": [
    "def reverse_with_model(sentence, model, tokenizer, device='mps'):\n",
    "    # Encode the input text and move tensor to the specified device\n",
    "    input_ids = tokenizer.encode(\"reverse: \" + sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate outputs and ensure the model is on the correct device\n",
    "    model = model.to(device)\n",
    "    outputs = model.generate(input_ids)\n",
    "\n",
    "    # Decode the generated ids\n",
    "    reversed_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return reversed_sentence\n",
    "\n",
    "test_sentence = \"Hello world\"\n",
    "reversed_sentence = reverse_with_model(test_sentence, model, tokenizer)\n",
    "print(f\"Original: {test_sentence}\")\n",
    "print(f\"Reversed: {reversed_sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./trained_model/tokenizer_config.json',\n",
       " './trained_model/special_tokens_map.json',\n",
       " './trained_model/spiece.model',\n",
       " './trained_model/added_tokens.json',\n",
       " './trained_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./trained_model\")\n",
    "tokenizer.save_pretrained(\"./trained_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
